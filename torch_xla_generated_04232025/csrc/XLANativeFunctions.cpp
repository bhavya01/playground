// @generated by lazy_tensor_generator.py from DispatchKeyNativeFunctions.cpp
#include "torch_xla/csrc/tensor.h"
#include <torch/csrc/lazy/core/shape_inference.h>
#include <ATen/Functions.h>
#include <ATen/native/TensorConversions.h>
#include <ATen/NativeFunctions.h>
#include <ATen/CompositeExplicitAutogradNonFunctionalFunctions.h>
#include <ATen/MetaFunctions.h>
#include <ATen/Operators.h>
#include <ATen/native/CPUFallback.h>
#include <torch/csrc/lazy/core/ir_builder.h>
#include <torch/csrc/lazy/core/lazy_graph_executor.h>
#include <torch/csrc/lazy/core/metrics.h>
#include <torch/csrc/lazy/core/shape.h>
#include "bazel-out/k8-opt/bin/torch_xla/csrc/XLANativeFunctions.h"
#include "bazel-out/k8-opt/bin/torch_xla/csrc/LazyIr.h"


namespace {
at::Tensor to_meta(const at::Tensor& tensor) {
  // undefined tensors can't be converted to the meta device, since they don't have sizes/strides
  if (!tensor.defined()) return tensor;
  auto out = at::native::empty_strided_meta_symint(tensor.sym_sizes(), tensor.sym_strides(), /*dtype=*/tensor.scalar_type(), /*layout=*/tensor.layout(), /*device=*/c10::Device(c10::kMeta), /*pin_memory=*/std::nullopt);
  // needs to handle wrapped numbers, so dtype promotion works properly.
  if (tensor.unsafeGetTensorImpl()->is_wrapped_number()) {
    out.unsafeGetTensorImpl()->set_wrapped_number(true);
  }
  return out;
}
std::optional<at::Tensor> to_meta(const std::optional<at::Tensor>& tensor) {
  if (tensor.has_value()) {
    return to_meta(*tensor);
  }
  return std::nullopt;
}

std::vector<at::Tensor> to_meta(at::ITensorListRef t_list) {
  std::vector<at::Tensor> outs;
  outs.reserve(t_list.size());
  for (const auto& tensor : t_list) {
    outs.push_back(to_meta(tensor));
  }
  return outs;
}
} // namespace

namespace torch_xla {

    at::Tensor XLANativeFunctions::_conj_copy(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<ConjCopy>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<ConjCopy>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::abs(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Abs>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Abs>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::acos(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Acos>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Acos>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::acosh(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Acosh>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Acosh>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::addcdiv(const at::Tensor & self, const at::Tensor & tensor1, const at::Tensor & tensor2, const at::Scalar & value) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self, tensor1, tensor2);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch_xla::XLATensorPtr lazy_tensor1 = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(tensor1, *common_device);
        torch_xla::XLATensorPtr lazy_tensor2 = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(tensor2, *common_device);
        auto node_value = torch::lazy::LazyGraphExecutor::Get()->
                            GetIrValueForScalarFromCodegen(value, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Addcdiv>(lazy_self->GetIrValue(), lazy_tensor1->GetIrValue(), lazy_tensor2->GetIrValue(), node_value);
      if (!node) {
          
          node = torch_xla::MakeNode<Addcdiv>(lazy_self->GetIrValue(), lazy_tensor1->GetIrValue(), lazy_tensor2->GetIrValue(), node_value);
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::addcmul(const at::Tensor & self, const at::Tensor & tensor1, const at::Tensor & tensor2, const at::Scalar & value) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self, tensor1, tensor2);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch_xla::XLATensorPtr lazy_tensor1 = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(tensor1, *common_device);
        torch_xla::XLATensorPtr lazy_tensor2 = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(tensor2, *common_device);
        auto node_value = torch::lazy::LazyGraphExecutor::Get()->
                            GetIrValueForScalarFromCodegen(value, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Addcmul>(lazy_self->GetIrValue(), lazy_tensor1->GetIrValue(), lazy_tensor2->GetIrValue(), node_value);
      if (!node) {
          
          node = torch_xla::MakeNode<Addcmul>(lazy_self->GetIrValue(), lazy_tensor1->GetIrValue(), lazy_tensor2->GetIrValue(), node_value);
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::all(const at::Tensor & self, int64_t dim, bool keepdim) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<AllDim>(lazy_self->GetIrValue(), dim, keepdim);
      if (!node) {
          
          node = torch_xla::MakeNode<AllDim>(lazy_self->GetIrValue(), dim, keepdim);
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::all(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<All>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<All>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::amax(const at::Tensor & self, at::IntArrayRef dim, bool keepdim) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Amax>(lazy_self->GetIrValue(), std::vector<int64_t>(dim.begin(), dim.end()), keepdim);
      if (!node) {
          
          node = torch_xla::MakeNode<Amax>(lazy_self->GetIrValue(), std::vector<int64_t>(dim.begin(), dim.end()), keepdim);
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::amin(const at::Tensor & self, at::IntArrayRef dim, bool keepdim) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Amin>(lazy_self->GetIrValue(), std::vector<int64_t>(dim.begin(), dim.end()), keepdim);
      if (!node) {
          
          node = torch_xla::MakeNode<Amin>(lazy_self->GetIrValue(), std::vector<int64_t>(dim.begin(), dim.end()), keepdim);
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::any(const at::Tensor & self, int64_t dim, bool keepdim) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<AnyDim>(lazy_self->GetIrValue(), dim, keepdim);
      if (!node) {
          
          node = torch_xla::MakeNode<AnyDim>(lazy_self->GetIrValue(), dim, keepdim);
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::any(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Any>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Any>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::argmax(const at::Tensor & self, ::std::optional<int64_t> dim, bool keepdim) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Argmax>(lazy_self->GetIrValue(), dim, keepdim);
      if (!node) {
          
          node = torch_xla::MakeNode<Argmax>(lazy_self->GetIrValue(), dim, keepdim);
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::argmin(const at::Tensor & self, ::std::optional<int64_t> dim, bool keepdim) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Argmin>(lazy_self->GetIrValue(), dim, keepdim);
      if (!node) {
          
          node = torch_xla::MakeNode<Argmin>(lazy_self->GetIrValue(), dim, keepdim);
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::asin(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Asin>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Asin>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::asinh(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Asinh>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Asinh>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::atan(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Atan>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Atan>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::atanh(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Atanh>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Atanh>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::binary_cross_entropy(const at::Tensor & self, const at::Tensor & target, const ::std::optional<at::Tensor> & weight, int64_t reduction) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self, target, weight);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch_xla::XLATensorPtr lazy_target = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(target, *common_device);
        torch_xla::XLATensorPtr lazy_weight = torch_xla::bridge::TryGetXlaTensor(weight.value_or(at::Tensor()));
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<BinaryCrossEntropy>(lazy_self->GetIrValue(), lazy_target->GetIrValue(), lazy_weight ? std::make_optional(lazy_weight->GetIrValue()) : ::std::nullopt, reduction);
      if (!node) {
          
          node = torch_xla::MakeNode<BinaryCrossEntropy>(lazy_self->GetIrValue(), lazy_target->GetIrValue(), lazy_weight ? std::make_optional(lazy_weight->GetIrValue()) : ::std::nullopt, reduction);
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::binary_cross_entropy_backward(const at::Tensor & grad_output, const at::Tensor & self, const at::Tensor & target, const ::std::optional<at::Tensor> & weight, int64_t reduction) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(grad_output, self, target, weight);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_grad_output = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(grad_output, *common_device);
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch_xla::XLATensorPtr lazy_target = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(target, *common_device);
        torch_xla::XLATensorPtr lazy_weight = torch_xla::bridge::TryGetXlaTensor(weight.value_or(at::Tensor()));
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<BinaryCrossEntropyBackward>(lazy_grad_output->GetIrValue(), lazy_self->GetIrValue(), lazy_target->GetIrValue(), lazy_weight ? std::make_optional(lazy_weight->GetIrValue()) : ::std::nullopt, reduction);
      if (!node) {
          
          node = torch_xla::MakeNode<BinaryCrossEntropyBackward>(lazy_grad_output->GetIrValue(), lazy_self->GetIrValue(), lazy_target->GetIrValue(), lazy_weight ? std::make_optional(lazy_weight->GetIrValue()) : ::std::nullopt, reduction);
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::bitwise_left_shift(const at::Tensor & self, const at::Tensor & other) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self, other);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch_xla::XLATensorPtr lazy_other = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(other, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<BitwiseLeftShiftTensor>(lazy_self->GetIrValue(), lazy_other->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<BitwiseLeftShiftTensor>(lazy_self->GetIrValue(), lazy_other->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::bitwise_not(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<BitwiseNot>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<BitwiseNot>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::bitwise_right_shift(const at::Tensor & self, const at::Tensor & other) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self, other);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch_xla::XLATensorPtr lazy_other = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(other, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<BitwiseRightShiftTensor>(lazy_self->GetIrValue(), lazy_other->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<BitwiseRightShiftTensor>(lazy_self->GetIrValue(), lazy_other->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::ceil(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Ceil>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Ceil>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::cholesky(const at::Tensor & self, bool upper) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Cholesky>(lazy_self->GetIrValue(), upper);
      if (!node) {
          
          node = torch_xla::MakeNode<Cholesky>(lazy_self->GetIrValue(), upper);
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::clamp(const at::Tensor & self, const ::std::optional<at::Tensor> & min, const ::std::optional<at::Tensor> & max) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self, min, max);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch_xla::XLATensorPtr lazy_min = torch_xla::bridge::TryGetXlaTensor(min.value_or(at::Tensor()));
        torch_xla::XLATensorPtr lazy_max = torch_xla::bridge::TryGetXlaTensor(max.value_or(at::Tensor()));
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<ClampTensor>(lazy_self->GetIrValue(), lazy_min ? std::make_optional(lazy_min->GetIrValue()) : ::std::nullopt, lazy_max ? std::make_optional(lazy_max->GetIrValue()) : ::std::nullopt);
      if (!node) {
          
          node = torch_xla::MakeNode<ClampTensor>(lazy_self->GetIrValue(), lazy_min ? std::make_optional(lazy_min->GetIrValue()) : ::std::nullopt, lazy_max ? std::make_optional(lazy_max->GetIrValue()) : ::std::nullopt);
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::clamp_max(const at::Tensor & self, const at::Tensor & max) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self, max);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch_xla::XLATensorPtr lazy_max = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(max, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<ClampMaxTensor>(lazy_self->GetIrValue(), lazy_max->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<ClampMaxTensor>(lazy_self->GetIrValue(), lazy_max->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::clamp_min(const at::Tensor & self, const at::Tensor & min) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self, min);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch_xla::XLATensorPtr lazy_min = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(min, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<ClampMinTensor>(lazy_self->GetIrValue(), lazy_min->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<ClampMinTensor>(lazy_self->GetIrValue(), lazy_min->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::cos(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Cos>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Cos>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::cosh(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Cosh>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Cosh>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::elu(const at::Tensor & self, const at::Scalar & alpha, const at::Scalar & scale, const at::Scalar & input_scale) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        auto node_alpha = torch::lazy::LazyGraphExecutor::Get()->
                            GetIrValueForScalarFromCodegen(alpha, *common_device);
        auto node_scale = torch::lazy::LazyGraphExecutor::Get()->
                            GetIrValueForScalarFromCodegen(scale, *common_device);
        auto node_input_scale = torch::lazy::LazyGraphExecutor::Get()->
                            GetIrValueForScalarFromCodegen(input_scale, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Elu>(lazy_self->GetIrValue(), node_alpha, node_scale, node_input_scale);
      if (!node) {
          
          node = torch_xla::MakeNode<Elu>(lazy_self->GetIrValue(), node_alpha, node_scale, node_input_scale);
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::eq(const at::Tensor & self, const at::Scalar & other) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        auto node_other = torch::lazy::LazyGraphExecutor::Get()->
                            GetIrValueForScalarFromCodegen(other, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<EqScalar>(lazy_self->GetIrValue(), node_other);
      if (!node) {
          
          node = torch_xla::MakeNode<EqScalar>(lazy_self->GetIrValue(), node_other);
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::eq(const at::Tensor & self, const at::Tensor & other) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self, other);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch_xla::XLATensorPtr lazy_other = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(other, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<EqTensor>(lazy_self->GetIrValue(), lazy_other->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<EqTensor>(lazy_self->GetIrValue(), lazy_other->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::erf(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Erf>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Erf>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::erfc(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Erfc>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Erfc>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::erfinv(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Erfinv>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Erfinv>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::exp(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Exp>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Exp>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::expm1(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Expm1>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Expm1>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::floor(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Floor>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Floor>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::frac(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Frac>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Frac>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::ge(const at::Tensor & self, const at::Scalar & other) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        auto node_other = torch::lazy::LazyGraphExecutor::Get()->
                            GetIrValueForScalarFromCodegen(other, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<GeScalar>(lazy_self->GetIrValue(), node_other);
      if (!node) {
          
          node = torch_xla::MakeNode<GeScalar>(lazy_self->GetIrValue(), node_other);
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::ge(const at::Tensor & self, const at::Tensor & other) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self, other);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch_xla::XLATensorPtr lazy_other = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(other, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<GeTensor>(lazy_self->GetIrValue(), lazy_other->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<GeTensor>(lazy_self->GetIrValue(), lazy_other->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::glu(const at::Tensor & self, int64_t dim) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Glu>(lazy_self->GetIrValue(), dim);
      if (!node) {
          
          node = torch_xla::MakeNode<Glu>(lazy_self->GetIrValue(), dim);
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::gt(const at::Tensor & self, const at::Scalar & other) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        auto node_other = torch::lazy::LazyGraphExecutor::Get()->
                            GetIrValueForScalarFromCodegen(other, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<GtScalar>(lazy_self->GetIrValue(), node_other);
      if (!node) {
          
          node = torch_xla::MakeNode<GtScalar>(lazy_self->GetIrValue(), node_other);
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::gt(const at::Tensor & self, const at::Tensor & other) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self, other);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch_xla::XLATensorPtr lazy_other = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(other, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<GtTensor>(lazy_self->GetIrValue(), lazy_other->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<GtTensor>(lazy_self->GetIrValue(), lazy_other->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::hardshrink(const at::Tensor & self, const at::Scalar & lambd) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        auto node_lambd = torch::lazy::LazyGraphExecutor::Get()->
                            GetIrValueForScalarFromCodegen(lambd, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Hardshrink>(lazy_self->GetIrValue(), node_lambd);
      if (!node) {
          
          node = torch_xla::MakeNode<Hardshrink>(lazy_self->GetIrValue(), node_lambd);
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::hardshrink_backward(const at::Tensor & grad_out, const at::Tensor & self, const at::Scalar & lambd) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(grad_out, self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_grad_out = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(grad_out, *common_device);
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        auto node_lambd = torch::lazy::LazyGraphExecutor::Get()->
                            GetIrValueForScalarFromCodegen(lambd, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<HardshrinkBackward>(lazy_grad_out->GetIrValue(), lazy_self->GetIrValue(), node_lambd);
      if (!node) {
          
          node = torch_xla::MakeNode<HardshrinkBackward>(lazy_grad_out->GetIrValue(), lazy_self->GetIrValue(), node_lambd);
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::hardsigmoid(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Hardsigmoid>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Hardsigmoid>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::hardsigmoid_backward(const at::Tensor & grad_output, const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(grad_output, self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_grad_output = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(grad_output, *common_device);
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<HardsigmoidBackward>(lazy_grad_output->GetIrValue(), lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<HardsigmoidBackward>(lazy_grad_output->GetIrValue(), lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::hardswish(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Hardswish>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Hardswish>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::hardswish_backward(const at::Tensor & grad_output, const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(grad_output, self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_grad_output = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(grad_output, *common_device);
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<HardswishBackward>(lazy_grad_output->GetIrValue(), lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<HardswishBackward>(lazy_grad_output->GetIrValue(), lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::inverse(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Inverse>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Inverse>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::isnan(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Isnan>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Isnan>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::isneginf(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Isneginf>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Isneginf>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::le(const at::Tensor & self, const at::Scalar & other) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        auto node_other = torch::lazy::LazyGraphExecutor::Get()->
                            GetIrValueForScalarFromCodegen(other, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<LeScalar>(lazy_self->GetIrValue(), node_other);
      if (!node) {
          
          node = torch_xla::MakeNode<LeScalar>(lazy_self->GetIrValue(), node_other);
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::le(const at::Tensor & self, const at::Tensor & other) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self, other);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch_xla::XLATensorPtr lazy_other = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(other, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<LeTensor>(lazy_self->GetIrValue(), lazy_other->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<LeTensor>(lazy_self->GetIrValue(), lazy_other->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::leaky_relu(const at::Tensor & self, const at::Scalar & negative_slope) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        auto node_negative_slope = torch::lazy::LazyGraphExecutor::Get()->
                            GetIrValueForScalarFromCodegen(negative_slope, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<LeakyRelu>(lazy_self->GetIrValue(), node_negative_slope);
      if (!node) {
          
          node = torch_xla::MakeNode<LeakyRelu>(lazy_self->GetIrValue(), node_negative_slope);
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::log_sigmoid_backward(const at::Tensor & grad_output, const at::Tensor & self, const at::Tensor & buffer) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(grad_output, self, buffer);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_grad_output = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(grad_output, *common_device);
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch_xla::XLATensorPtr lazy_buffer = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(buffer, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<LogSigmoidBackward>(lazy_grad_output->GetIrValue(), lazy_self->GetIrValue(), lazy_buffer->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<LogSigmoidBackward>(lazy_grad_output->GetIrValue(), lazy_self->GetIrValue(), lazy_buffer->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    ::std::tuple<at::Tensor,at::Tensor> XLANativeFunctions::log_sigmoid_forward(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<LogSigmoidForward>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<LogSigmoidForward>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        std::vector<torch_xla::XLATensorPtr> lazy_tensors;
        for (int i = 0; i < 2; i++) {
            lazy_tensors.push_back(torch_xla::XLATensor::Create(torch::lazy::Value(node, i), *common_device));
        }
        auto result = torch_xla::bridge::TupleAtenFromXlaTensors<2>(lazy_tensors);
        return result;
    }

    
    at::Tensor XLANativeFunctions::logdet(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Logdet>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Logdet>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::logical_and(const at::Tensor & self, const at::Tensor & other) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self, other);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch_xla::XLATensorPtr lazy_other = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(other, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<LogicalAnd>(lazy_self->GetIrValue(), lazy_other->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<LogicalAnd>(lazy_self->GetIrValue(), lazy_other->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::logical_not(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<LogicalNot>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<LogicalNot>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::logical_or(const at::Tensor & self, const at::Tensor & other) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self, other);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch_xla::XLATensorPtr lazy_other = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(other, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<LogicalOr>(lazy_self->GetIrValue(), lazy_other->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<LogicalOr>(lazy_self->GetIrValue(), lazy_other->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::logical_xor(const at::Tensor & self, const at::Tensor & other) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self, other);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch_xla::XLATensorPtr lazy_other = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(other, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<LogicalXor>(lazy_self->GetIrValue(), lazy_other->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<LogicalXor>(lazy_self->GetIrValue(), lazy_other->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::lt(const at::Tensor & self, const at::Scalar & other) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        auto node_other = torch::lazy::LazyGraphExecutor::Get()->
                            GetIrValueForScalarFromCodegen(other, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<LtScalar>(lazy_self->GetIrValue(), node_other);
      if (!node) {
          
          node = torch_xla::MakeNode<LtScalar>(lazy_self->GetIrValue(), node_other);
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::lt(const at::Tensor & self, const at::Tensor & other) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self, other);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch_xla::XLATensorPtr lazy_other = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(other, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<LtTensor>(lazy_self->GetIrValue(), lazy_other->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<LtTensor>(lazy_self->GetIrValue(), lazy_other->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::masked_fill(const at::Tensor & self, const at::Tensor & mask, const at::Scalar & value) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self, mask);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch_xla::XLATensorPtr lazy_mask = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(mask, *common_device);
        auto node_value = torch::lazy::LazyGraphExecutor::Get()->
                            GetIrValueForScalarFromCodegen(value, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<MaskedFillScalar>(lazy_self->GetIrValue(), lazy_mask->GetIrValue(), node_value);
      if (!node) {
          
          node = torch_xla::MakeNode<MaskedFillScalar>(lazy_self->GetIrValue(), lazy_mask->GetIrValue(), node_value);
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::masked_fill(const at::Tensor & self, const at::Tensor & mask, const at::Tensor & value) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self, mask, value);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch_xla::XLATensorPtr lazy_mask = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(mask, *common_device);
        torch_xla::XLATensorPtr lazy_value = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(value, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<MaskedFillTensor>(lazy_self->GetIrValue(), lazy_mask->GetIrValue(), lazy_value->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<MaskedFillTensor>(lazy_self->GetIrValue(), lazy_mask->GetIrValue(), lazy_value->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::maximum(const at::Tensor & self, const at::Tensor & other) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self, other);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch_xla::XLATensorPtr lazy_other = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(other, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Maximum>(lazy_self->GetIrValue(), lazy_other->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Maximum>(lazy_self->GetIrValue(), lazy_other->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::minimum(const at::Tensor & self, const at::Tensor & other) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self, other);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch_xla::XLATensorPtr lazy_other = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(other, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Minimum>(lazy_self->GetIrValue(), lazy_other->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Minimum>(lazy_self->GetIrValue(), lazy_other->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::native_dropout_backward(const at::Tensor & grad_output, const at::Tensor & mask, double scale) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(grad_output, mask);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_grad_output = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(grad_output, *common_device);
        torch_xla::XLATensorPtr lazy_mask = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(mask, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<NativeDropoutBackward>(lazy_grad_output->GetIrValue(), lazy_mask->GetIrValue(), scale);
      if (!node) {
          
          node = torch_xla::MakeNode<NativeDropoutBackward>(lazy_grad_output->GetIrValue(), lazy_mask->GetIrValue(), scale);
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::ne(const at::Tensor & self, const at::Scalar & other) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        auto node_other = torch::lazy::LazyGraphExecutor::Get()->
                            GetIrValueForScalarFromCodegen(other, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<NeScalar>(lazy_self->GetIrValue(), node_other);
      if (!node) {
          
          node = torch_xla::MakeNode<NeScalar>(lazy_self->GetIrValue(), node_other);
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::ne(const at::Tensor & self, const at::Tensor & other) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self, other);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch_xla::XLATensorPtr lazy_other = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(other, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<NeTensor>(lazy_self->GetIrValue(), lazy_other->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<NeTensor>(lazy_self->GetIrValue(), lazy_other->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::reciprocal(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Reciprocal>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Reciprocal>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::relu(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Relu>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Relu>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::repeat(const at::Tensor & self, at::IntArrayRef repeats) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Repeat>(lazy_self->GetIrValue(), std::vector<int64_t>(repeats.begin(), repeats.end()));
      if (!node) {
          
          node = torch_xla::MakeNode<Repeat>(lazy_self->GetIrValue(), std::vector<int64_t>(repeats.begin(), repeats.end()));
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::round(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Round>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Round>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::rsqrt(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Rsqrt>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Rsqrt>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::selu(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Selu>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Selu>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::sgn(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Sgn>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Sgn>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::sigmoid(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Sigmoid>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Sigmoid>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::sign(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Sign>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Sign>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::silu(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Silu>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Silu>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::silu_backward(const at::Tensor & grad_output, const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(grad_output, self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_grad_output = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(grad_output, *common_device);
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<SiluBackward>(lazy_grad_output->GetIrValue(), lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<SiluBackward>(lazy_grad_output->GetIrValue(), lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::sin(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Sin>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Sin>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::sinh(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Sinh>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Sinh>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::softshrink(const at::Tensor & self, const at::Scalar & lambd) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        auto node_lambd = torch::lazy::LazyGraphExecutor::Get()->
                            GetIrValueForScalarFromCodegen(lambd, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Softshrink>(lazy_self->GetIrValue(), node_lambd);
      if (!node) {
          
          node = torch_xla::MakeNode<Softshrink>(lazy_self->GetIrValue(), node_lambd);
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::softshrink_backward(const at::Tensor & grad_output, const at::Tensor & self, const at::Scalar & lambd) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(grad_output, self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_grad_output = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(grad_output, *common_device);
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        auto node_lambd = torch::lazy::LazyGraphExecutor::Get()->
                            GetIrValueForScalarFromCodegen(lambd, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<SoftshrinkBackward>(lazy_grad_output->GetIrValue(), lazy_self->GetIrValue(), node_lambd);
      if (!node) {
          
          node = torch_xla::MakeNode<SoftshrinkBackward>(lazy_grad_output->GetIrValue(), lazy_self->GetIrValue(), node_lambd);
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::sqrt(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Sqrt>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Sqrt>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::take(const at::Tensor & self, const at::Tensor & index) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self, index);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch_xla::XLATensorPtr lazy_index = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(index, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Take>(lazy_self->GetIrValue(), lazy_index->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Take>(lazy_self->GetIrValue(), lazy_index->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::tan(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Tan>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Tan>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::tanh(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Tanh>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Tanh>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::tril(const at::Tensor & self, int64_t diagonal) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Tril>(lazy_self->GetIrValue(), diagonal);
      if (!node) {
          
          node = torch_xla::MakeNode<Tril>(lazy_self->GetIrValue(), diagonal);
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::triu(const at::Tensor & self, int64_t diagonal) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Triu>(lazy_self->GetIrValue(), diagonal);
      if (!node) {
          
          node = torch_xla::MakeNode<Triu>(lazy_self->GetIrValue(), diagonal);
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

    
    at::Tensor XLANativeFunctions::trunc(const at::Tensor & self) {
        
        TORCH_LAZY_FN_COUNTER_TIMED_TRACING("xla::");
        auto common_device = torch_xla::bridge::GetXlaDevice(self);
        TORCH_INTERNAL_ASSERT(common_device);
        
        torch_xla::XLATensorPtr lazy_self = torch_xla::bridge::GetXlaTensorOrCreateForWrappedNumber(self, *common_device);
        torch::lazy::NodePtr node = torch::lazy::ReuseNode<Trunc>(lazy_self->GetIrValue());
      if (!node) {
          
          node = torch_xla::MakeNode<Trunc>(lazy_self->GetIrValue());
          CacheNode(node);
      }
      
        auto result = torch_xla::bridge::AtenFromXlaTensor(
                torch_xla::XLATensor::Create(std::move(node), *common_device));
        return result;
    }

} // namespace torch_xla
